{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"posterlayout\"\n",
    "task = \"content\"\n",
    "input_format = \"seq\"\n",
    "output_format = \"html\"\n",
    "add_unk_token = False\n",
    "add_index_token = True\n",
    "add_sep_token = True\n",
    "candidate_size = -1  # -1 represents the complete training set\n",
    "num_prompt = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from preprocess import create_processor\n",
    "from utils import RAW_DATA_PATH, read_pt, write_pt\n",
    "from pandas import read_csv\n",
    "\n",
    "metadata = read_csv(os.path.join(RAW_DATA_PATH(dataset), \"train_csv_9973.csv\"))\n",
    "processor = create_processor(dataset, task, metadata=metadata)\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "\n",
    "def get_processed_data(split):\n",
    "    filename = os.path.join(\n",
    "        base_dir, \"dataset\", dataset, \"processed\", task, f\"{split}.pt\"\n",
    "    )\n",
    "    if os.path.exists(filename):\n",
    "        processed_data = read_pt(filename)\n",
    "    else:\n",
    "        processed_data = []\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        raw_path = os.path.join(RAW_DATA_PATH(dataset), split, \"saliencymaps_pfpn\")\n",
    "        raw_data = os.listdir(raw_path)\n",
    "        raw_data = sorted(raw_data, key=lambda x: int(x.split(\"_\")[0]))\n",
    "        for rd in tqdm(raw_data, desc=f\"{split} data processing...\"):\n",
    "            idx = int(rd.split(\"_\")[0])\n",
    "            data = processor(os.path.join(raw_path, rd), idx, split)\n",
    "            if data:\n",
    "                processed_data.append(data)\n",
    "        write_pt(filename, processed_data)\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "processed_train_data = get_processed_data(\"train\")\n",
    "processed_test_data = get_processed_data(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic exemplar selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selection import create_selector\n",
    "\n",
    "\n",
    "selector = create_selector(\n",
    "    task=task,\n",
    "    train_data=processed_train_data,\n",
    "    candidate_size=candidate_size,\n",
    "    num_prompt=num_prompt,\n",
    ")\n",
    "\n",
    "test_idx = 0\n",
    "exemplars = selector(processed_test_data[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input-output serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serialization import create_serializer, build_prompt\n",
    "\n",
    "\n",
    "serializer = create_serializer(\n",
    "    dataset=dataset,\n",
    "    task=task,\n",
    "    input_format=input_format,\n",
    "    output_format=output_format,\n",
    "    add_index_token=add_index_token,\n",
    "    add_sep_token=add_sep_token,\n",
    "    add_unk_token=add_unk_token\n",
    ")\n",
    "prompt = build_prompt(serializer, exemplars, processed_test_data[test_idx], dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install unsloth\n",
    "%pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "import torch\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    %pip install --no-deps packaging ninja einops \"flash-attn>=2.6.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gemma 2b quantized model\n",
    "from unsloth import FastLanguageModel\n",
    "max_seq_length = 2048 \n",
    "dtype = None \n",
    "load_in_4bit = True \n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-2-2b\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = prompt + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "response = model.generate(**inputs, max_new_tokens = 800, use_cache = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsing import Parser\n",
    "\n",
    "\n",
    "parser = Parser(dataset=dataset, output_format=output_format)\n",
    "parsed_response = parser(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layout ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranker import Ranker\n",
    "\n",
    "\n",
    "val_path = os.path.join(RAW_DATA_PATH(dataset), \"val.pt\")\n",
    "ranker = Ranker(val_path=val_path)\n",
    "ranked_response = ranker(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import Visualizer, create_image_grid\n",
    "\n",
    "\n",
    "visualizer = Visualizer(dataset)\n",
    "images = visualizer(ranked_response)\n",
    "create_image_grid(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
